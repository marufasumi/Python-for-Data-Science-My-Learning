{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3901bf4a",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=Bc2Gey7bmhk&list=PLfFghEzKVmjubeylqAapjPc95q8TBXsnR&index=4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3429ef",
   "metadata": {},
   "source": [
    "## Module:1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6563faa2",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "=> Deep learning is a subfield of Machine Learning that uses Artificial Neural Networks to learn from the data.\n",
    "=> Application of DL\n",
    "Healthcare: Radiology (CNN) -> Computer vision\n",
    "Autonomous car\n",
    "\n",
    "=>Main Types of Neural network:\n",
    "-Convolutional Neural Network(CNN): mainly used for computer vision task\n",
    "-Recurrent neural Network(RNN): perform well in text data set\n",
    "-Generative Adversarial Network(GAN): They can generate new image and video generation task\n",
    "-Transfer Learning:use pretrained model\n",
    "\n",
    "Framework for DL:\n",
    "-TensorFlow (google)\n",
    "-PyTorch (Facebook)\n",
    "-CNTK\n",
    "-keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001aca79",
   "metadata": {},
   "source": [
    "### DL -1.2  How Neural Network Works?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dea7324",
   "metadata": {},
   "source": [
    "input layer-> multiple hidden layer -> output layer\n",
    "\n",
    "Activation Function: Sigmoid ...\n",
    "\n",
    "Forward propagation\n",
    "\n",
    "Backword propagation\n",
    "\n",
    "one Epoc: forward propagation of all images and backword propagation of all images.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0f8787",
   "metadata": {},
   "source": [
    "### DL-1.3 Perceptron in Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db04607",
   "metadata": {},
   "source": [
    "=> Deep learning and Perceptron\n",
    "\n",
    "=> what is perceptron\n",
    "\n",
    "=>Mathmetical representation of perceptron\n",
    "\n",
    "=>Activation Functions used in a Perceptron"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db2fa7cc",
   "metadata": {},
   "source": [
    "## Perceptron\n",
    "\n",
    "Percepron is nothing but most basic unit of a neural network.(neuron)\n",
    "\n",
    "A perceptron is basic artificial neuron that takes inputs, applies weights,combines them and produces an output using an \n",
    "\n",
    "activation function. It is used for tasks like binary classification and is a building block of neural networks.\n",
    "\n",
    "#### Factors:\n",
    "\n",
    "=> input\n",
    "\n",
    "=> weights: signifies how imporatnt the input feature is\n",
    "\n",
    "=> bias : bias is always a single value\n",
    "\n",
    "=>weighted sum\n",
    "\n",
    "=> Activation\n",
    "\n",
    "=>Output\n",
    "\n",
    "\n",
    "Mathematical representation:\n",
    "\n",
    "#### Activation Function:\n",
    "\n",
    "Activation function calculates \"weighted sum\" of it's input, adds a bias and then decides weather a neuron should be activated or not.\n",
    "\n",
    "The purpose of activation funtion is to introduce non-linearity into output of a neuron.\n",
    "\n",
    "##### Why do we need non-linear activation function\n",
    "\n",
    "A neural network without an activation function is essentially just a linear regression model.\n",
    "\n",
    "With this non-linear transformation, the neural network is capable of learning and performing more complex tasks.\n",
    "\n",
    "Five main actication Functions:\n",
    "\n",
    "1. Linear : y=ax\n",
    "\n",
    "No matter how many layers we have, if all the layers are  linear in nature then the final activation function of last layer is nothing but just a linear function of input layer.\n",
    "\n",
    "Range: -inf to +inf\n",
    "\n",
    "uses: Used at just one place i.e output layer\n",
    "\n",
    "issues:  If we differentiate a linear function to bring non-linearity, then the result will no more dependent on input\"x\" and function will become constant, it won't introduce any-ground breaking behaviour to our algorithm.\n",
    "\n",
    "2. Sogmoid\n",
    "\n",
    "nature: Non linear\n",
    "\n",
    "Range: 0 to 1\n",
    "\n",
    "Uses: In the output layer of a binary classification\n",
    "\n",
    "3. Tanh\n",
    "\n",
    "Most of the time tanh function works better than the sigmoid function, also known as Tangent Hyperbolic Function.\n",
    "\n",
    "Mathematically this function is a shifted version of sigmoid function. Both are similar functions and can be derived from each other.\n",
    "\n",
    "nature: Non-linear\n",
    "\n",
    "range: 0 to 1\n",
    "\n",
    "Uses: Used in hidden layers, as it's values lies between -1 to 1. Mean for hidden lear comes 0 or very close to 0, hence it helps to center the data close to 0.\n",
    "\n",
    "\n",
    "4. reLu\n",
    "\n",
    "It is widely used activation function\n",
    "\n",
    "range: 0 to inf\n",
    "\n",
    "nature: Non-linear,we can easily backpropagate errors and multiple layers of neuron being activated by the reLU function.\n",
    "\n",
    "uses: Computationally less expensive than tanh and sigmoid function because, At the time only few neurons are activated.\n",
    "\n",
    "5. Softmax\n",
    "\n",
    "Type of sigmoid function but it is handy when we are dealing with the classifications problems.\n",
    "\n",
    "Nature: Non-linear\n",
    "\n",
    "Uses: Used in multiple class scenario\n",
    "\n",
    "Output: Ideally used in output layer of the classifier, where we are trying to attain the probabilities to define the class of each input.\n",
    "\n",
    "Sigmoid Function: Output is a continuous value that lies between 0 and 1.\n",
    "\n",
    "Step Function: Output is binary(0 or 1) based on a theshold.\n",
    "\n",
    "Sign Function: Output is binary(-1 or 1) based on the sign of the input.\n",
    "\n",
    "ReLu(Rectified Linear Unit) function:Output is the input value if it is positive else 0\n",
    "\n",
    "\n",
    "#### Loss Function\n",
    "\n",
    "\n",
    "#### Optimization Algorithm\n",
    "\n",
    "Gradiant Decent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d786d0e5",
   "metadata": {},
   "source": [
    "### Selecting right activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb414f0",
   "metadata": {},
   "source": [
    "=> If you really don't know which activation funcction to use, then use reLU,as it is a general activation function and used in most cases.\n",
    "\n",
    "=> If your output is for binary classification, then use sigmoid function for output layer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0058c24a",
   "metadata": {},
   "source": [
    "## Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a4d898",
   "metadata": {},
   "source": [
    "The cost function measures the performance of Machine Learning model for a given data.\n",
    "\n",
    "It quantifies the error between predicted values and expexted values, it presents result in the form of a single real number\n",
    "\n",
    "We use the Cost function to measure the performance of a Machine Learning Model.\n",
    "\n",
    "##### Quadratic Cost Function:\n",
    "\n",
    "##### Cross Entropy Cost Function\n",
    "\n",
    "It is better than Quardatic cost function.\n",
    "\n",
    "\n",
    "##Now we know that there are two key aspects with which a neural network learns\n",
    "\n",
    "1. Activation Function\n",
    "\n",
    "2. Cost Function\n",
    "\n",
    "we are still missing a key step, that is \"The actual learning process\"\n",
    "\n",
    "Now we have to figure out a way, so we can use cost function (error) and neurons to attempt the correct prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ebdb21",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18009ff4",
   "metadata": {},
   "source": [
    "=> Key aspects with which a neural network learns\n",
    "\n",
    "1. Cost Function\n",
    "\n",
    "2. Activation Function\n",
    "\n",
    "we are still missing a key step, that is \"The actual learning process\"\n",
    "\n",
    "To understand the learning process we have to understand the gradient descent.\n",
    "\n",
    "=>The gradient descent is an optimization algorithm that is used for minimizing the cost function(error)\n",
    "\n",
    "=> It updates the various parameters of Machine learning model to minimize the cost function.\n",
    "\n",
    "=> Finding the minimum value of a cost function looks very simple in 1 dimension, but in our cases we will have multiple parameters (dimension)\n",
    "\n",
    "=> So we will use the built-in linear algebra libraries in deep learning to minimize the cost function.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8d099b",
   "metadata": {},
   "source": [
    "### Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df039054",
   "metadata": {},
   "source": [
    "=> Using gradient descent we can figure out the best parameters for minimizing the cost function.\n",
    "\n",
    "=> How can we adjust the optimal parameters or weights accross the entire network?\n",
    "\n",
    "=> To do that we use backpropagation.\n",
    "\n",
    "=> Backpropagation is used to calculate the error contribution of each neuron after a batch of data is processed.\n",
    "\n",
    "=> It calculates error at output and then distributes that output back throughout the network layers.\n",
    "\n",
    "=> To do that , it requires a known desired output for each input value (supervised learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8535dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
