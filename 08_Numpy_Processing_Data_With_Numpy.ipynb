{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f919a140",
   "metadata": {},
   "source": [
    "### Processing Data With Numpy"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0848af7a",
   "metadata": {},
   "source": [
    "=> Two ways to import CSV file\n",
    "np.loadtxt() vs np.genformtxt()\n",
    "\n",
    "=> Both functions are part of the numpy package\n",
    "=> \"load\" implies the data is ready to be directly imported and used\n",
    "\n",
    "=> \"generate\" indicates that the function creates the dataset from the text file\n",
    "=> generating requires constructing the array aswe go through the text file\n",
    "=> np.load is faster while np.genformtext has more flexibility\n",
    "\n",
    "file name\n",
    "Typically stored in the same directory as your python notebook\n",
    "if not you'd have to specify the entire path leading to the file you want to import\n",
    "delimeters\n",
    "Pre-defined symbols (e.g \",\" and\";\" which are used to define distinc fields in text files(cells in a row, rows in a table)\n",
    "A very common approach is to store large datasets in text files this way (text separated by delimiters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8149c7",
   "metadata": {},
   "source": [
    "### Importing Data With  numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c75804f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f9058c",
   "metadata": {},
   "source": [
    "##### np.loadtxt() vs np.genformtxt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c16dee37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_company_data_numeric_1 = np.loadtxt(\"Lending-Company-Numeric-Data.csv\", delimiter=',')\n",
    "lending_company_data_numeric_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbe75605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_company_data_numeric_2 = np.genfromtxt(\"Lending-Company-Numeric-Data.csv\", delimiter=',')\n",
    "lending_company_data_numeric_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29996104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check if the arrays are equal or not\n",
    "np.array_equal(lending_company_data_numeric_1,lending_company_data_numeric_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e676232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why does it matter which method should we use\n",
    "# load method is faster but it breaks when we feed it incomplete or ill-formatted datasets\n",
    "# where generatefromtext method is slower but can handle the missing values\n",
    "# NAN = Not a number, Refers to missing values within a Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9ce1e62",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15236\\4062397998.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlending_company_data_numeric_1_NAN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Lending-Company-Numeric-Data-NAN.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m';'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, like)\u001b[0m\n\u001b[0;32m   1146\u001b[0m         \u001b[1;31m# converting the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1148\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mread_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_loadtxt_chunksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1149\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mread_data\u001b[1;34m(chunk_size)\u001b[0m\n\u001b[0;32m    997\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m             \u001b[1;31m# Convert each value according to its column and store\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m             \u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m             \u001b[1;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    997\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m             \u001b[1;31m# Convert each value according to its column and store\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m             \u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m             \u001b[1;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mfloatconv\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    734\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'0x'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromhex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m     \u001b[0mtyp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "lending_company_data_numeric_1_NAN = np.loadtxt(\"Lending-Company-Numeric-Data-NAN.csv\", delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2418f1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ValueError: could not convert string to float: '' means Python encounters a symbol when it expects a number\n",
    "# missing values =\"\"(empty space) => empty space count as a symbol\n",
    "# To ways to solve this error\n",
    "# use genfromtxt method or \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e65f1cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [   nan,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_company_data_numeric_1_NAN = np.genfromtxt(\"Lending-Company-Numeric-Data-NAN.csv\", delimiter=';')\n",
    "lending_company_data_numeric_1_NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "805922ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['2000', '40', '365', '3121', '4241', '13621'],\n",
       "       ['2000', '40', '365', '3061', '4171', '15041'],\n",
       "       ['1000', '40', '365', '2160', '3280', '15340'],\n",
       "       ...,\n",
       "       ['', '40', '365', '4201', '5001', '16600'],\n",
       "       ['1000', '40', '365', '2080', '3320', '15600'],\n",
       "       ['2000', '40', '365', '4601', '4601', '16600']], dtype='<U5')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#or specify the datatype as string\n",
    "# We can use this way of importing dataset only if we want to observe the data values that have been stored in it, \n",
    "#and we don't need to execute any mathematical operation\n",
    "# They are saved as plain text rather than numbers\n",
    "# All the values now have single quotes around them\n",
    "# That's why it's crucial to make sure that we import our data in the most appropriate type\n",
    "lending_company_data_numeric_1_NAN = np.loadtxt(\"Lending-Company-Numeric-Data-NAN.csv\", delimiter=';', dtype=np.str_)\n",
    "lending_company_data_numeric_1_NAN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25549f2d",
   "metadata": {},
   "source": [
    "### Partial cleaning of data when important "
   ]
  },
  {
   "cell_type": "raw",
   "id": "4c88035a",
   "metadata": {},
   "source": [
    "# Beneficial when we're familiar with our data\n",
    "np.genfromtxt()\n",
    "skip_header\n",
    "skip_footer\n",
    "usecols\n",
    "unpack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4c8b4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [   nan,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_company_data_numeric_1_NAN = np.genfromtxt(\"Lending-Company-Numeric-Data-NAN.csv\", delimiter=';')\n",
    "lending_company_data_numeric_1_NAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c871600c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       [ 2000.,    40.,   365.,  3041.,  4241., 15321.],\n",
       "       [ 2000.,    50.,   365.,  3470.,  4820., 13720.],\n",
       "       ...,\n",
       "       [   nan,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skip_header =2 should remove the first two line of the dataset, it can be any number\n",
    "lending_company_data_numeric_1_NAN = np.genfromtxt(\"Lending-Company-Numeric-Data-NAN.csv\", delimiter=';', \n",
    "                                                                                           skip_header=2)\n",
    "lending_company_data_numeric_1_NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33ca532f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  3401.,    nan, 16600.],\n",
       "       [ 2000.,    40.,   365.,    nan,  5440., 16600.],\n",
       "       [   nan,    40.,   365.,  4201.,  5001., 16600.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skip_footer =2 should remove the first two line of the dataset from the bottom, it can be any number\n",
    "lending_company_data_numeric_1_NAN = np.genfromtxt(\"Lending-Company-Numeric-Data-NAN.csv\", delimiter=';', \n",
    "                                                                                           skip_footer=2)\n",
    "lending_company_data_numeric_1_NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0db47a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40., 13621.],\n",
       "       [ 2000.,    40., 15041.],\n",
       "       [ 1000.,    40., 15340.],\n",
       "       ...,\n",
       "       [   nan,    40., 16600.],\n",
       "       [ 1000.,    40., 15600.],\n",
       "       [ 2000.,    40., 16600.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# usecols =0  means it will say python we are only interested in the first column\n",
    "# put all the values we are interested  in parenthesis\n",
    "# python uses 0 indexing\n",
    "# we can also change the order of the column \n",
    "lending_company_data_numeric_1_NAN = np.genfromtxt(\"Lending-Company-Numeric-Data-NAN.csv\", delimiter=';', \n",
    "                                                                                           usecols=(0,1,5))\n",
    "                                                                                        \n",
    "lending_company_data_numeric_1_NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06e541db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000., 13621.,  3121.],\n",
       "       [ 2000., 15041.,  3061.],\n",
       "       [ 1000., 15340.,  2160.],\n",
       "       ...,\n",
       "       [   nan, 16600.,  4201.],\n",
       "       [ 1000., 15600.,  2080.],\n",
       "       [ 2000., 16600.,  4601.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_company_data_numeric_1_NAN = np.genfromtxt(\"Lending-Company-Numeric-Data-NAN.csv\", delimiter=';', \n",
    "                                                                                           usecols=(0,5,3))\n",
    "                                                                                       \n",
    "lending_company_data_numeric_1_NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8987acf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3a365ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1000., 15340.,  2160.],\n",
       "       [ 2000., 15321.,  3041.],\n",
       "       [ 2000., 13720.,  3470.],\n",
       "       ...,\n",
       "       [ 2000., 16600.,  3401.],\n",
       "       [ 2000., 16600.,    nan],\n",
       "       [   nan, 16600.,  4201.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_company_data_numeric_1_NAN = np.genfromtxt(\"Lending-Company-Numeric-Data-NAN.csv\", delimiter=';', \n",
    "                                                                                           usecols=(0,5,3),\n",
    "                                                                                           skip_header=2,\n",
    "                                                                                           skip_footer=2)\n",
    "                                                                                       \n",
    "lending_company_data_numeric_1_NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7fc81608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to split each one/column into individual variable , unpack=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98fe0117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000. 2000. 2000. ... 2000. 2000.   nan]\n",
      "[15340. 15321. 13720. ... 16600. 16600. 16600.]\n",
      "[2160. 3041. 3470. ... 3401.   nan 4201.]\n"
     ]
    }
   ],
   "source": [
    "lending_company_data_0,lending_company_data_5,lending_company_data_3 = np.genfromtxt(\"Lending-Company-Numeric-Data-NAN.csv\", delimiter=';', \n",
    "                                                                                           usecols=(0,5,3),\n",
    "                                                                                           skip_header=2,\n",
    "                                                                                           skip_footer=2, unpack =True)\n",
    "\n",
    "print(lending_compay_data_0)\n",
    "print(lending_company_data_5)\n",
    "print(lending_company_data_3)\n",
    "                                                                                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f6a71b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is important to rememeber that the output is generated and then unpacked according to the order of the usecols argument"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e8e005",
   "metadata": {},
   "source": [
    "### Importing data with Numpy-String vs Object Vs Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d094962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[      nan,       nan,       nan, ...,       nan,       nan,\n",
       "              nan],\n",
       "       [1.000e+00,       nan,       nan, ...,       nan,       nan,\n",
       "        1.660e+04],\n",
       "       [2.000e+00,       nan,       nan, ...,       nan,       nan,\n",
       "        1.660e+04],\n",
       "       ...,\n",
       "       [1.041e+03,       nan,       nan, ...,       nan,       nan,\n",
       "        1.660e+04],\n",
       "       [1.042e+03,       nan,       nan, ...,       nan,       nan,\n",
       "        1.560e+04],\n",
       "       [1.043e+03,       nan,       nan, ...,       nan,       nan,\n",
       "        1.660e+04]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_lt = np.genfromtxt(\"lending-co-LT.csv\", delimiter =',')\n",
    "lending_co_lt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be1cf4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[      nan       nan       nan ...       nan       nan       nan]\n",
      " [1.000e+00       nan       nan ...       nan       nan 1.660e+04]\n",
      " [2.000e+00       nan       nan ...       nan       nan 1.660e+04]\n",
      " ...\n",
      " [1.041e+03       nan       nan ...       nan       nan 1.660e+04]\n",
      " [1.042e+03       nan       nan ...       nan       nan 1.560e+04]\n",
      " [1.043e+03       nan       nan ...       nan       nan 1.660e+04]]\n"
     ]
    }
   ],
   "source": [
    "print(lending_co_lt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d7e3aa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "lending_co_lt = np.genfromtxt(\"lending-co-LT.csv\", delimiter =',', dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ba4cbeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   -1    -1    -1 ...    -1    -1    -1]\n",
      " [    1    -1    -1 ...    -1    -1 16600]\n",
      " [    2    -1    -1 ...    -1    -1 16600]\n",
      " ...\n",
      " [ 1041    -1    -1 ...    -1    -1 16600]\n",
      " [ 1042    -1    -1 ...    -1    -1 15600]\n",
      " [ 1043    -1    -1 ...    -1    -1 16600]]\n"
     ]
    }
   ],
   "source": [
    "## By specifting the input data to be a specific type , the funtion genertaes the missing values diffrently\n",
    "#We need to be careful when we ask python  to perform computations afetr we have imported missing values catagorized as integers\n",
    "print(lending_co_lt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ed55297a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_lt[0,0] +lending_co_lt[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "645bb7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the entire dataset as text\n",
    "# We can not add the values up or do other mathematical operations\n",
    "# However diffrent elements within the array can still be sorted , cut and formatted\n",
    "lending_co_lt = np.genfromtxt(\"lending-co-LT.csv\", delimiter =',', dtype=np.str_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d60aeae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['LoanID' 'StringID' 'Product' ... 'Location' 'Region' 'TotalPrice']\n",
      " ['1' 'id_1' 'Product B' ... 'Location 2' 'Region 2' '16600.0']\n",
      " ['2' 'id_2' 'Product B' ... 'Location 3' '' '16600.0']\n",
      " ...\n",
      " ['1041' 'id_1041' 'Product B' ... 'Location 23' 'Region 4' '16600.0']\n",
      " ['1042' 'id_1042' 'Product C' ... 'Location 52' 'Region 6' '15600.0']\n",
      " ['1043' 'id_1043' 'Product B' ... 'Location 142' 'Region 6' '16600.0']]\n"
     ]
    }
   ],
   "source": [
    "print(lending_co_lt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ba6fab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the data as object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a1457463",
   "metadata": {},
   "outputs": [],
   "source": [
    "lending_co_lt = np.genfromtxt(\"lending-co-LT.csv\", delimiter =',', dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b8023edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[b'LoanID' b'StringID' b'Product' ... b'Location' b'Region'\n",
      "  b'TotalPrice']\n",
      " [b'1' b'id_1' b'Product B' ... b'Location 2' b'Region 2' b'16600.0']\n",
      " [b'2' b'id_2' b'Product B' ... b'Location 3' b'' b'16600.0']\n",
      " ...\n",
      " [b'1041' b'id_1041' b'Product B' ... b'Location 23' b'Region 4'\n",
      "  b'16600.0']\n",
      " [b'1042' b'id_1042' b'Product C' ... b'Location 52' b'Region 6'\n",
      "  b'15600.0']\n",
      " [b'1043' b'id_1043' b'Product B' ... b'Location 142' b'Region 6'\n",
      "  b'16600.0']]\n"
     ]
    }
   ],
   "source": [
    "print(lending_co_lt) # b indicate that data inside is not just plain text so we can freely manupulate the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6a544959",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can also import the dataset as an array of multiple types\n",
    "#The number of datatypes is determined by the number of columns or field in the dataset\n",
    "# Array usally consist of a single numeric datatype\n",
    "# We should avoid specifying variuos datatypes when working with the Numpy package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9d0d8386",
   "metadata": {},
   "outputs": [],
   "source": [
    "lending_co_lt = np.genfromtxt(\"lending-co-LT.csv\", delimiter =',', dtype=(np.int32, np.str_,np.str_,np.str_,np.str_,np.str_,np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1026ab6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(  -1, '', '', '', '', '',    -1) (   1, '', '', '', '', '', 16600)\n",
      " (   2, '', '', '', '', '', 16600) ... (1041, '', '', '', '', '', 16600)\n",
      " (1042, '', '', '', '', '', 15600) (1043, '', '', '', '', '', 16600)]\n"
     ]
    }
   ],
   "source": [
    "print(lending_co_lt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fb0295",
   "metadata": {},
   "source": [
    "## Saving Data With Numpy-NPY\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "14a94b2c",
   "metadata": {},
   "source": [
    "np.save(\"file name\", dataset_variable) \n",
    "\n",
    "=>Creates an file-name.npy file in the same directory(folder) as your notebook(.ipytnb) document\n",
    "=>npy is a special type of text file native to numpy\n",
    "=> npy is a much faster\n",
    "=> npy takes less memory space than CSV or text file\n",
    "=> CSV and other text files are still exteremly useful when preprocessing and analyzing data with other libraries (or programming languages)\n",
    "=> Load dataset != Import a dataset\n",
    "Importing does not keep track of the original array. That's why we may need to specify the datatype of the values after having \n",
    "brought them into python\n",
    "=> When loading, we don't need to specify or change our data while working with our pyhton object\n",
    "=> The most convinient feature of npy: As they are native to numpy the entire dataset keeps it format.So we don't need to worry\n",
    "about specifying and reorganizing the values from the external text file\n",
    "e.g Suppose we store certain parts of dataset as numbers. Npy is technically a text file. When we load the dataset back into python it will consider them as numbers automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "826d09aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['LoanID' 'StringID' 'Product' ... 'Location' 'Region' 'TotalPrice']\n",
      " ['1' 'id_1' 'Product B' ... 'Location 2' 'Region 2' '16600.0']\n",
      " ['2' 'id_2' 'Product B' ... 'Location 3' '' '16600.0']\n",
      " ...\n",
      " ['1041' 'id_1041' 'Product B' ... 'Location 23' 'Region 4' '16600.0']\n",
      " ['1042' 'id_1042' 'Product C' ... 'Location 52' 'Region 6' '15600.0']\n",
      " ['1043' 'id_1043' 'Product B' ... 'Location 142' 'Region 6' '16600.0']]\n"
     ]
    }
   ],
   "source": [
    "lending_co = np.genfromtxt(\"Lending-Company-Saving.csv\", delimiter=',', dtype =np.str_)\n",
    "print(lending_co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "348a3d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"Lending-Company-Saving\", lending_co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "66473d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "lending_data_save =np.load(\"Lending-Company-Saving.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ed379c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['LoanID' 'StringID' 'Product' ... 'Location' 'Region' 'TotalPrice']\n",
      " ['1' 'id_1' 'Product B' ... 'Location 2' 'Region 2' '16600.0']\n",
      " ['2' 'id_2' 'Product B' ... 'Location 3' '' '16600.0']\n",
      " ...\n",
      " ['1041' 'id_1041' 'Product B' ... 'Location 23' 'Region 4' '16600.0']\n",
      " ['1042' 'id_1042' 'Product C' ... 'Location 52' 'Region 6' '15600.0']\n",
      " ['1043' 'id_1043' 'Product B' ... 'Location 142' 'Region 6' '16600.0']]\n"
     ]
    }
   ],
   "source": [
    "print(lending_data_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aa3cfc7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To check if both dataset are identical\n",
    "np.array_equal(lending_data_save,lending_co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "76edf8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This means the data is unaltered after we saved it and loaded it back in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bfcffc",
   "metadata": {},
   "source": [
    "### Saving Data With Numpy-NPZ"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9962cb4",
   "metadata": {},
   "source": [
    "np.savez()  .npz\n",
    "=> npz is like an archive of NPYs that can store multiple arrays\n",
    "=> hence, instead of storing diffrent datasets in separtae NPY files, we can store all of them in a single NPZ.\n",
    "=> NPZs can be very helpful when working with large amount of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d6855e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['LoanID' 'StringID' 'Product' ... 'Location' 'Region' 'TotalPrice']\n",
      " ['1' 'id_1' 'Product B' ... 'Location 2' 'Region 2' '16600.0']\n",
      " ['2' 'id_2' 'Product B' ... 'Location 3' '' '16600.0']\n",
      " ...\n",
      " ['1041' 'id_1041' 'Product B' ... 'Location 23' 'Region 4' '16600.0']\n",
      " ['1042' 'id_1042' 'Product C' ... 'Location 52' 'Region 6' '15600.0']\n",
      " ['1043' 'id_1043' 'Product B' ... 'Location 142' 'Region 6' '16600.0']]\n"
     ]
    }
   ],
   "source": [
    "lending_co = np.genfromtxt(\"Lending-Company-Saving.csv\", delimiter=',', dtype =np.str_)\n",
    "print(lending_co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "718af35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"Lending-Company-Saving\", lending_co) # we can use  lending_data_save as an input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0c35d908",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"Lending-Company-Saving\", lending_co, lending_data_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ff7c6c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "lending_data_savez =np.load(\"Lending-Company-Saving.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9a8b2efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<numpy.lib.npyio.NpzFile object at 0x000001B4FFEF9940>\n"
     ]
    }
   ],
   "source": [
    "print(lending_data_savez) # Why is that so\n",
    "#beacuse npz contained a collection of arrays. It can't be properly displayed this way\n",
    "# We must specify the array we want to open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a2745624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['LoanID' 'StringID' 'Product' ... 'Location' 'Region' 'TotalPrice']\n",
      " ['1' 'id_1' 'Product B' ... 'Location 2' 'Region 2' '16600.0']\n",
      " ['2' 'id_2' 'Product B' ... 'Location 3' '' '16600.0']\n",
      " ...\n",
      " ['1041' 'id_1041' 'Product B' ... 'Location 23' 'Region 4' '16600.0']\n",
      " ['1042' 'id_1042' 'Product C' ... 'Location 52' 'Region 6' '15600.0']\n",
      " ['1043' 'id_1043' 'Product B' ... 'Location 142' 'Region 6' '16600.0']]\n"
     ]
    }
   ],
   "source": [
    "print(lending_data_savez[\"arr_0\"]) # for index 0 array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a50037e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['LoanID' 'StringID' 'Product' ... 'Location' 'Region' 'TotalPrice']\n",
      " ['1' 'id_1' 'Product B' ... 'Location 2' 'Region 2' '16600.0']\n",
      " ['2' 'id_2' 'Product B' ... 'Location 3' '' '16600.0']\n",
      " ...\n",
      " ['1041' 'id_1041' 'Product B' ... 'Location 23' 'Region 4' '16600.0']\n",
      " ['1042' 'id_1042' 'Product C' ... 'Location 52' 'Region 6' '15600.0']\n",
      " ['1043' 'id_1043' 'Product B' ... 'Location 142' 'Region 6' '16600.0']]\n"
     ]
    }
   ],
   "source": [
    "print(lending_data_savez[\"arr_1\"]) # for second array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "153bac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is beacuse by f=default NPZ files stores each dataset as a separate array witha gneric name\n",
    "## We we want to set distinguble name for each one we do so by defining keyword argument for each array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9515660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"Lending-Company-Saving\",company= lending_co, data_save=lending_data_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9f37883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lending_data_savez =np.load(\"Lending-Company-Saving.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1157f7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['company', 'data_save']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_data_savez.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "99ecdbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['LoanID' 'StringID' 'Product' ... 'Location' 'Region' 'TotalPrice']\n",
      " ['1' 'id_1' 'Product B' ... 'Location 2' 'Region 2' '16600.0']\n",
      " ['2' 'id_2' 'Product B' ... 'Location 3' '' '16600.0']\n",
      " ...\n",
      " ['1041' 'id_1041' 'Product B' ... 'Location 23' 'Region 4' '16600.0']\n",
      " ['1042' 'id_1042' 'Product C' ... 'Location 52' 'Region 6' '15600.0']\n",
      " ['1043' 'id_1043' 'Product B' ... 'Location 142' 'Region 6' '16600.0']]\n"
     ]
    }
   ],
   "source": [
    "print(lending_data_savez[\"company\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c7c05367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['LoanID' 'StringID' 'Product' ... 'Location' 'Region' 'TotalPrice']\n",
      " ['1' 'id_1' 'Product B' ... 'Location 2' 'Region 2' '16600.0']\n",
      " ['2' 'id_2' 'Product B' ... 'Location 3' '' '16600.0']\n",
      " ...\n",
      " ['1041' 'id_1041' 'Product B' ... 'Location 23' 'Region 4' '16600.0']\n",
      " ['1042' 'id_1042' 'Product C' ... 'Location 52' 'Region 6' '15600.0']\n",
      " ['1043' 'id_1043' 'Product B' ... 'Location 142' 'Region 6' '16600.0']]\n"
     ]
    }
   ],
   "source": [
    "print(lending_data_savez[\"data_save\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4a175d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(lending_data_savez[\"company\"],lending_data_savez[\"data_save\"])# The data remains the same even after saving and reloading it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0871b16c",
   "metadata": {},
   "source": [
    "## Saving Data With Numpy - CSV"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d7cb3531",
   "metadata": {},
   "source": [
    "np.savetxt()\n",
    "=> hepls to strore Numpy dataset in text files .txt or .csv format\n",
    "=> The syntax is once again very familiar to np.save() and np.savez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d1797635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['LoanID' 'StringID' 'Product' ... 'Location' 'Region' 'TotalPrice']\n",
      " ['1' 'id_1' 'Product B' ... 'Location 2' 'Region 2' '16600.0']\n",
      " ['2' 'id_2' 'Product B' ... 'Location 3' '' '16600.0']\n",
      " ...\n",
      " ['1041' 'id_1041' 'Product B' ... 'Location 23' 'Region 4' '16600.0']\n",
      " ['1042' 'id_1042' 'Product C' ... 'Location 52' 'Region 6' '15600.0']\n",
      " ['1043' 'id_1043' 'Product B' ... 'Location 142' 'Region 6' '16600.0']]\n"
     ]
    }
   ],
   "source": [
    "lending_co = np.genfromtxt(\"Lending-Company-Saving.csv\", delimiter=',', dtype =np.str_)\n",
    "print(lending_co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ccc4a974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to specify the file extension during saving\n",
    "np.savetxt(\"Lending-Company-Saving.txt\", lending_co, fmt='%s', delimiter=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "010e9714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt requires importing the file rather than loading it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c5ad0640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['LoanID' 'StringID' 'Product' ... 'Location' 'Region' 'TotalPrice']\n",
      " ['1' 'id_1' 'Product B' ... 'Location 2' 'Region 2' '16600.0']\n",
      " ['2' 'id_2' 'Product B' ... 'Location 3' '' '16600.0']\n",
      " ...\n",
      " ['1041' 'id_1041' 'Product B' ... 'Location 23' 'Region 4' '16600.0']\n",
      " ['1042' 'id_1042' 'Product C' ... 'Location 52' 'Region 6' '15600.0']\n",
      " ['1043' 'id_1043' 'Product B' ... 'Location 142' 'Region 6' '16600.0']]\n"
     ]
    }
   ],
   "source": [
    "lending_data_savetxt =np.genfromtxt(\"Lending-Company-Saving.txt\",delimiter=',', dtype=np.str_)\n",
    "\n",
    "print(lending_data_savetxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "46db25e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lending_data_save =np.load(\"Lending-Company-Saving.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c1077ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(lending_data_savetxt, lending_data_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95d5425",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
